{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ca6d5776852b6ffd",
   "metadata": {},
   "source": [
    "## **Keywords extraction using semantic search**\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffb1b0dd5976af3a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-19T02:12:12.521640Z",
     "start_time": "2025-04-18T20:57:34.426652Z"
    }
   },
   "outputs": [],
   "source": [
    "from keyword_extractor import extract_and_save_keywords_with_semantic_search\n",
    "dream_df = extract_and_save_keywords_with_semantic_search()\n",
    "dream_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f82f11ce8bbf2da",
   "metadata": {},
   "source": [
    "The dataframe is too large (too many unnecessary columns). Let's view only the interesting ones:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6a20d25e95d905f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-19T15:06:18.951883Z",
     "start_time": "2025-04-19T15:06:18.896741Z"
    }
   },
   "outputs": [],
   "source": [
    "from yaml_parser import load_config\n",
    "config = load_config()\n",
    "columns_to_show = [config['data']['keywords_column'], config['data']['dream_text_column']]\n",
    "dream_df[columns_to_show]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a476ac17d8fd87de",
   "metadata": {},
   "source": [
    "well, a quick observation at the results shows that some of the dreams gained a too diverged keywords, and some are not diverged enough. We wll try to change the diversity factor and/or the size of the semantic search output. We will do it on samples of 100 rows of the data just to show the change."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eb54c637d2c9c83",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-19T15:58:11.607725Z",
     "start_time": "2025-04-19T15:51:13.331841Z"
    }
   },
   "outputs": [],
   "source": [
    "from keyword_extractor import extract_keywords_with_semantic_search, read_datasets\n",
    "import torch\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from IPython.display import display, Markdown\n",
    "import pandas as pd\n",
    "\n",
    "# Set display options for DataFrames\n",
    "pd.set_option(\"display.max_columns\", None)  # Show all columns\n",
    "pd.set_option(\"display.max_rows\", None)     # Show all rows\n",
    "pd.set_option(\"display.max_colwidth\", None) # Do not truncate column contents\n",
    "\n",
    "dream_df, keywords_df = read_datasets(config)\n",
    "\n",
    "config = load_config()\n",
    "rseeds = [11, 22, 33, 44, 55, 66, 77, 88, 99]\n",
    "candidate_keywords = keywords_df[config['data']['keywords_column']].dropna().unique().tolist()\n",
    "\n",
    "# Load model\n",
    "model_name = config['model']['name']\n",
    "model = SentenceTransformer(model_name)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "\n",
    "# Encode keywords\n",
    "keywords_embeddings = model.encode(candidate_keywords, convert_to_tensor=True, device=model.device.type)\n",
    "\n",
    "# Extract keywords from each dream using semantic search\n",
    "top_k_semantic = config['model']['num_semantic']    # 50\n",
    "top_n_mmr = config['model']['num_keywords']         # 5\n",
    "diversity = config['model']['diversity']            # 0.5\n",
    "\n",
    "\n",
    "for rs in rseeds:\n",
    "    sample = dream_df.sample(100, random_state=rs)\n",
    "    results = []\n",
    "\n",
    "    for dream in sample[config['data']['dream_text_column']]:\n",
    "        keywords = extract_keywords_with_semantic_search(dream, keywords_embeddings, candidate_keywords, model, top_k_semantic, top_n_mmr, diversity)\n",
    "        results.append(\",\".join(keywords))\n",
    "\n",
    "    sample[config['data']['keywords_column']] = results\n",
    "    display(Markdown(f\"#### **{top_k_semantic=}, {diversity=}, {rs=}**\\n***\"))\n",
    "    display(sample[columns_to_show])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e63dbbbc06e178f7",
   "metadata": {},
   "source": [
    "it seems like it only made worse.. let's try to lower the diversity even more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72275a4acab04e31",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-19T16:21:28.885797Z",
     "start_time": "2025-04-19T16:14:26.017178Z"
    }
   },
   "outputs": [],
   "source": [
    "from keyword_extractor import extract_keywords_with_semantic_search, read_datasets\n",
    "import torch\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from IPython.display import display, Markdown\n",
    "import pandas as pd\n",
    "\n",
    "# Set display options for DataFrames\n",
    "pd.set_option(\"display.max_columns\", None)  # Show all columns\n",
    "pd.set_option(\"display.max_rows\", None)     # Show all rows\n",
    "pd.set_option(\"display.max_colwidth\", None) # Do not truncate column contents\n",
    "\n",
    "dream_df, keywords_df = read_datasets(config)\n",
    "\n",
    "config = load_config()\n",
    "rseeds = [11, 22, 33, 44, 55, 66, 77, 88, 99]\n",
    "candidate_keywords = keywords_df[config['data']['keywords_column']].dropna().unique().tolist()\n",
    "\n",
    "# Load model\n",
    "model_name = config['model']['name']\n",
    "model = SentenceTransformer(model_name)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "\n",
    "# Encode keywords\n",
    "keywords_embeddings = model.encode(candidate_keywords, convert_to_tensor=True, device=model.device.type)\n",
    "\n",
    "# Extract keywords from each dream using semantic search\n",
    "top_k_semantic = config['model']['num_semantic']    # 50\n",
    "top_n_mmr = config['model']['num_keywords']         # 5\n",
    "diversity = config['model']['diversity']            # 0.3\n",
    "\n",
    "\n",
    "for rs in rseeds:\n",
    "    sample = dream_df.sample(100, random_state=rs)\n",
    "    results = []\n",
    "\n",
    "    for dream in sample[config['data']['dream_text_column']]:\n",
    "        keywords = extract_keywords_with_semantic_search(dream, keywords_embeddings, candidate_keywords, model, top_k_semantic, top_n_mmr, diversity)\n",
    "        results.append(\",\".join(keywords))\n",
    "\n",
    "    sample[config['data']['keywords_column']] = results\n",
    "    display(Markdown(f\"#### **{top_k_semantic=}, {diversity=}, {rs=}**\\n***\"))\n",
    "    display(sample[columns_to_show])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa9e6ae9a63bdd4c",
   "metadata": {},
   "source": [
    "A little better, but still not satisfying. Let's try to put the diversity factor back at 0.7 and increase the semantic search output to 20% of the keywords (which is 240)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be0a8fbf53e8be6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-19T17:01:49.576742Z",
     "start_time": "2025-04-19T16:29:56.961734Z"
    }
   },
   "outputs": [],
   "source": [
    "from keyword_extractor import extract_keywords_with_semantic_search, read_datasets\n",
    "import torch\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from IPython.display import display, Markdown\n",
    "import pandas as pd\n",
    "\n",
    "# Set display options for DataFrames\n",
    "pd.set_option(\"display.max_columns\", None)  # Show all columns\n",
    "pd.set_option(\"display.max_rows\", None)     # Show all rows\n",
    "pd.set_option(\"display.max_colwidth\", None) # Do not truncate column contents\n",
    "\n",
    "dream_df, keywords_df = read_datasets(config)\n",
    "\n",
    "config = load_config()\n",
    "rseeds = [11, 22, 33, 44, 55, 66, 77, 88, 99]\n",
    "candidate_keywords = keywords_df[config['data']['keywords_column']].dropna().unique().tolist()\n",
    "\n",
    "# Load model\n",
    "model_name = config['model']['name']\n",
    "model = SentenceTransformer(model_name)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "\n",
    "# Encode keywords\n",
    "keywords_embeddings = model.encode(candidate_keywords, convert_to_tensor=True, device=model.device.type)\n",
    "\n",
    "# Extract keywords from each dream using semantic search\n",
    "top_k_semantic = config['model']['num_semantic']    # 240\n",
    "top_n_mmr = config['model']['num_keywords']         # 5\n",
    "diversity = config['model']['diversity']            # 0.7\n",
    "\n",
    "\n",
    "for rs in rseeds:\n",
    "    sample = dream_df.sample(100, random_state=rs)\n",
    "    results = []\n",
    "\n",
    "    for dream in sample[config['data']['dream_text_column']]:\n",
    "        keywords = extract_keywords_with_semantic_search(dream, keywords_embeddings, candidate_keywords, model, top_k_semantic, top_n_mmr, diversity)\n",
    "        results.append(\",\".join(keywords))\n",
    "\n",
    "    sample[config['data']['keywords_column']] = results\n",
    "    display(Markdown(f\"#### **{top_k_semantic=}, {diversity=}, {rs=}**\\n***\"))\n",
    "    display(sample[columns_to_show])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2ffa2ec1d0608db",
   "metadata": {},
   "source": [
    "still not satisfying, let's try to lower the number of extracted keywords to the top 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c377d928e2756b0a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-19T17:13:45.427823Z",
     "start_time": "2025-04-19T17:07:49.144756Z"
    }
   },
   "outputs": [],
   "source": [
    "from keyword_extractor import extract_keywords_with_semantic_search, read_datasets\n",
    "import torch\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from IPython.display import display, Markdown\n",
    "import pandas as pd\n",
    "\n",
    "# Set display options for DataFrames\n",
    "pd.set_option(\"display.max_columns\", None)  # Show all columns\n",
    "pd.set_option(\"display.max_rows\", None)     # Show all rows\n",
    "pd.set_option(\"display.max_colwidth\", None) # Do not truncate column contents\n",
    "\n",
    "dream_df, keywords_df = read_datasets(config)\n",
    "\n",
    "config = load_config()\n",
    "rseeds = [11, 22, 33, 44, 55, 66, 77, 88, 99]\n",
    "candidate_keywords = keywords_df[config['data']['keywords_column']].dropna().unique().tolist()\n",
    "\n",
    "# Load model\n",
    "model_name = config['model']['name']\n",
    "model = SentenceTransformer(model_name)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "\n",
    "# Encode keywords\n",
    "keywords_embeddings = model.encode(candidate_keywords, convert_to_tensor=True, device=model.device.type)\n",
    "\n",
    "# Extract keywords from each dream using semantic search\n",
    "top_k_semantic = config['model']['num_semantic']    # 240\n",
    "top_n_mmr = config['model']['num_keywords']         # 3\n",
    "diversity = config['model']['diversity']            # 0.7\n",
    "\n",
    "\n",
    "for rs in rseeds:\n",
    "    sample = dream_df.sample(100, random_state=rs)\n",
    "    results = []\n",
    "\n",
    "    for dream in sample[config['data']['dream_text_column']]:\n",
    "        keywords = extract_keywords_with_semantic_search(dream, keywords_embeddings, candidate_keywords, model, top_k_semantic, top_n_mmr, diversity)\n",
    "        results.append(\",\".join(keywords))\n",
    "\n",
    "    sample[config['data']['keywords_column']] = results\n",
    "    display(Markdown(f\"#### **{top_k_semantic=}, {diversity=}, {rs=}**\\n***\"))\n",
    "    display(sample[columns_to_show])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aaecd40253a9533",
   "metadata": {},
   "source": [
    "well, it seems like we lost some valuable keywords. let's keep it 5 keywords but narrow the semantic search to 50."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a15bf0fa33da304d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-19T21:10:26.641331Z",
     "start_time": "2025-04-19T21:03:23.317704Z"
    }
   },
   "outputs": [],
   "source": [
    "from keyword_extractor import extract_keywords_with_semantic_search, read_datasets\n",
    "import torch\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from IPython.display import display, Markdown\n",
    "import pandas as pd\n",
    "\n",
    "# Set display options for DataFrames\n",
    "pd.set_option(\"display.max_columns\", None)  # Show all columns\n",
    "pd.set_option(\"display.max_rows\", None)     # Show all rows\n",
    "pd.set_option(\"display.max_colwidth\", None) # Do not truncate column contents\n",
    "\n",
    "dream_df, keywords_df = read_datasets(config)\n",
    "\n",
    "config = load_config()\n",
    "rseeds = [11, 22, 33, 44, 55, 66, 77, 88, 99]\n",
    "candidate_keywords = keywords_df[config['data']['keywords_column']].dropna().unique().tolist()\n",
    "\n",
    "# Load model\n",
    "model_name = config['model']['name']\n",
    "model = SentenceTransformer(model_name)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "\n",
    "# Encode keywords\n",
    "keywords_embeddings = model.encode(candidate_keywords, convert_to_tensor=True, device=model.device.type)\n",
    "\n",
    "# Extract keywords from each dream using semantic search\n",
    "top_k_semantic = config['model']['num_semantic']    # 50\n",
    "top_n_mmr = config['model']['num_keywords']         # 5\n",
    "diversity = config['model']['diversity']            # 0.7\n",
    "\n",
    "\n",
    "for rs in rseeds:\n",
    "    sample = dream_df.sample(100, random_state=rs)\n",
    "    results = []\n",
    "\n",
    "    for dream in sample[config['data']['dream_text_column']]:\n",
    "        keywords = extract_keywords_with_semantic_search(dream, keywords_embeddings, candidate_keywords, model, top_k_semantic, top_n_mmr, diversity)\n",
    "        results.append(\",\".join(keywords))\n",
    "\n",
    "    sample[config['data']['keywords_column']] = results\n",
    "    display(Markdown(f\"#### **{top_k_semantic=}, {diversity=}, {rs=}**\\n***\"))\n",
    "    display(sample[columns_to_show])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e77fed5cf8f8e071",
   "metadata": {},
   "source": [
    "it seems like narrowing the semantic search helped. let's try to narrow it down even more:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cfbe642c497f07c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-19T21:16:58.897530Z",
     "start_time": "2025-04-19T21:12:33.222348Z"
    }
   },
   "outputs": [],
   "source": [
    "from keyword_extractor import extract_keywords_with_semantic_search, read_datasets\n",
    "import torch\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from IPython.display import display, Markdown\n",
    "import pandas as pd\n",
    "\n",
    "# Set display options for DataFrames\n",
    "pd.set_option(\"display.max_columns\", None)  # Show all columns\n",
    "pd.set_option(\"display.max_rows\", None)     # Show all rows\n",
    "pd.set_option(\"display.max_colwidth\", None) # Do not truncate column contents\n",
    "\n",
    "dream_df, keywords_df = read_datasets(config)\n",
    "\n",
    "config = load_config()\n",
    "rseeds = [11, 22, 33, 44, 55, 66, 77, 88, 99]\n",
    "candidate_keywords = keywords_df[config['data']['keywords_column']].dropna().unique().tolist()\n",
    "\n",
    "# Load model\n",
    "model_name = config['model']['name']\n",
    "model = SentenceTransformer(model_name)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "\n",
    "# Encode keywords\n",
    "keywords_embeddings = model.encode(candidate_keywords, convert_to_tensor=True, device=model.device.type)\n",
    "\n",
    "# Extract keywords from each dream using semantic search\n",
    "top_k_semantic = config['model']['num_semantic']    # 30\n",
    "top_n_mmr = config['model']['num_keywords']         # 5\n",
    "diversity = config['model']['diversity']            # 0.7\n",
    "\n",
    "\n",
    "for rs in rseeds:\n",
    "    sample = dream_df.sample(100, random_state=rs)\n",
    "    results = []\n",
    "\n",
    "    for dream in sample[config['data']['dream_text_column']]:\n",
    "        keywords = extract_keywords_with_semantic_search(dream, keywords_embeddings, candidate_keywords, model, top_k_semantic, top_n_mmr, diversity)\n",
    "        results.append(\",\".join(keywords))\n",
    "\n",
    "    sample[config['data']['keywords_column']] = results\n",
    "    display(Markdown(f\"#### **{top_k_semantic=}, {diversity=}, {rs=}**\\n***\"))\n",
    "    display(sample[columns_to_show])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d1366514c9a0ea2",
   "metadata": {},
   "source": [
    "It seems like it was the best with semantic search of 50. We'll keep it that way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cccb9f84c1c1261",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2025-04-19T21:24:23.409085Z"
    },
    "jupyter": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "extract_and_save_keywords_with_semantic_search()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28fd4f74bc18a4a2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
