{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## **Step 1 - keywords Extraction**\n",
    "***"
   ],
   "id": "709bb27208e23ba4"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "We have two datasets, one with dream text descriptions:",
   "id": "b5af564d8f04df39"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-13T21:23:35.718332Z",
     "start_time": "2025-04-13T21:23:35.469996Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from keyword_extractor import read_datasets, extract_and_save_keywords_from_dataframes\n",
    "from yaml_parser import load_config\n",
    "config = load_config()\n",
    "dream_df, keywords_df = read_datasets(config)\n",
    "dream_df.head()"
   ],
   "id": "a1ecfbd7e24c7e53",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   dream_id dreamer               description dream_date dream_language  \\\n",
       "0         1    alta  Alta: a detailed dreamer       1957             en   \n",
       "1         2    alta  Alta: a detailed dreamer  8/11/1967             en   \n",
       "2         3    alta  Alta: a detailed dreamer   8/1/1985             en   \n",
       "3         4    alta  Alta: a detailed dreamer      1985?             en   \n",
       "4         5    alta  Alta: a detailed dreamer      1985?             en   \n",
       "\n",
       "                                          text_dream  \\\n",
       "0  The one at the Meads's house, where it's bigge...   \n",
       "1  I'm at a family reunion in a large fine house ...   \n",
       "2  I watch a plane fly past and shortly realize i...   \n",
       "3  Me pulling the green leaves and berries off so...   \n",
       "4  I'm in a room that reminds me of (but definite...   \n",
       "\n",
       "                                     characters_code  \\\n",
       "0                       2ISA, 1MKA, 1FDA, 1IOA, 2ISA   \n",
       "1                                 2ISA, people, 2ISA   \n",
       "2           2ISA, 2ISA, 1FSA, 1MBA, 1IOA, 2ISA, 2FDA   \n",
       "3  1MAA, 1FMA, 2ISA, 2IKA, 1ANI, 1ANI, 1IOA, 2ISA...   \n",
       "4                 1IRA, 1MSA, 1ISA, 2ISA, 1ISA, 1IKA   \n",
       "\n",
       "                           emotions_code  \\\n",
       "0                                    NaN   \n",
       "1                                SD 2IKA   \n",
       "2                    SD 1ISA, AP D, AP D   \n",
       "3                          SD 2ISA, SD D   \n",
       "4  AP D, AP D, AP 1MSA, CO D, SD D, AP D   \n",
       "\n",
       "                                     aggression_code        friendliness_code  \\\n",
       "0                                           2IKA > Q                2IKA 4> Q   \n",
       "1                                    D > Q, Q > 2ISA                      NaN   \n",
       "2                       It PRP >, It PRP >, D > 1FKA                      NaN   \n",
       "3                Q > Q, 2ISA > Q, 2ISA > Q, D > 1MSA  1IKA 4> Q, 2ISA 4> 2ISA   \n",
       "4  1MSA > D, Q > Q, D > 2IKA, D > 2IKA, D > 1MSA,...                   D 4> Q   \n",
       "\n",
       "   ...      Male    Animal   Friends    Family  Dead&Imaginary  \\\n",
       "0  ...  0.500000  0.000000  0.200000  0.200000             0.0   \n",
       "1  ...  0.000000  0.000000  0.000000  0.000000             0.0   \n",
       "2  ...  0.333333  0.000000  0.000000  0.285714             0.0   \n",
       "3  ...  0.666667  0.176471  0.142857  0.142857             0.0   \n",
       "4  ...  1.000000  0.000000  0.166667  0.166667             0.0   \n",
       "\n",
       "   Aggression/Friendliness  A/CIndex  F/CIndex  S/CIndex  NegativeEmotions  \n",
       "0                    0.000  0.200000  0.200000       0.0               0.0  \n",
       "1                    1.000  0.666667  0.000000       0.0               1.0  \n",
       "2                    1.000  0.428571  0.000000       0.0               1.0  \n",
       "3                    1.000  0.235294  0.117647       0.0               1.0  \n",
       "4                    0.875  1.333333  0.166667       0.0               1.0  \n",
       "\n",
       "[5 rows x 21 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dream_id</th>\n",
       "      <th>dreamer</th>\n",
       "      <th>description</th>\n",
       "      <th>dream_date</th>\n",
       "      <th>dream_language</th>\n",
       "      <th>text_dream</th>\n",
       "      <th>characters_code</th>\n",
       "      <th>emotions_code</th>\n",
       "      <th>aggression_code</th>\n",
       "      <th>friendliness_code</th>\n",
       "      <th>...</th>\n",
       "      <th>Male</th>\n",
       "      <th>Animal</th>\n",
       "      <th>Friends</th>\n",
       "      <th>Family</th>\n",
       "      <th>Dead&amp;Imaginary</th>\n",
       "      <th>Aggression/Friendliness</th>\n",
       "      <th>A/CIndex</th>\n",
       "      <th>F/CIndex</th>\n",
       "      <th>S/CIndex</th>\n",
       "      <th>NegativeEmotions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>alta</td>\n",
       "      <td>Alta: a detailed dreamer</td>\n",
       "      <td>1957</td>\n",
       "      <td>en</td>\n",
       "      <td>The one at the Meads's house, where it's bigge...</td>\n",
       "      <td>2ISA, 1MKA, 1FDA, 1IOA, 2ISA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2IKA &gt; Q</td>\n",
       "      <td>2IKA 4&gt; Q</td>\n",
       "      <td>...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>alta</td>\n",
       "      <td>Alta: a detailed dreamer</td>\n",
       "      <td>8/11/1967</td>\n",
       "      <td>en</td>\n",
       "      <td>I'm at a family reunion in a large fine house ...</td>\n",
       "      <td>2ISA, people, 2ISA</td>\n",
       "      <td>SD 2IKA</td>\n",
       "      <td>D &gt; Q, Q &gt; 2ISA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>alta</td>\n",
       "      <td>Alta: a detailed dreamer</td>\n",
       "      <td>8/1/1985</td>\n",
       "      <td>en</td>\n",
       "      <td>I watch a plane fly past and shortly realize i...</td>\n",
       "      <td>2ISA, 2ISA, 1FSA, 1MBA, 1IOA, 2ISA, 2FDA</td>\n",
       "      <td>SD 1ISA, AP D, AP D</td>\n",
       "      <td>It PRP &gt;, It PRP &gt;, D &gt; 1FKA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>alta</td>\n",
       "      <td>Alta: a detailed dreamer</td>\n",
       "      <td>1985?</td>\n",
       "      <td>en</td>\n",
       "      <td>Me pulling the green leaves and berries off so...</td>\n",
       "      <td>1MAA, 1FMA, 2ISA, 2IKA, 1ANI, 1ANI, 1IOA, 2ISA...</td>\n",
       "      <td>SD 2ISA, SD D</td>\n",
       "      <td>Q &gt; Q, 2ISA &gt; Q, 2ISA &gt; Q, D &gt; 1MSA</td>\n",
       "      <td>1IKA 4&gt; Q, 2ISA 4&gt; 2ISA</td>\n",
       "      <td>...</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.176471</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.235294</td>\n",
       "      <td>0.117647</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>alta</td>\n",
       "      <td>Alta: a detailed dreamer</td>\n",
       "      <td>1985?</td>\n",
       "      <td>en</td>\n",
       "      <td>I'm in a room that reminds me of (but definite...</td>\n",
       "      <td>1IRA, 1MSA, 1ISA, 2ISA, 1ISA, 1IKA</td>\n",
       "      <td>AP D, AP D, AP 1MSA, CO D, SD D, AP D</td>\n",
       "      <td>1MSA &gt; D, Q &gt; Q, D &gt; 2IKA, D &gt; 2IKA, D &gt; 1MSA,...</td>\n",
       "      <td>D 4&gt; Q</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.875</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "And another one with interpretations of dreams according to keywords:",
   "id": "62c56a04aa56a02"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-13T21:23:35.755134Z",
     "start_time": "2025-04-13T21:23:35.747133Z"
    }
   },
   "cell_type": "code",
   "source": "keywords_df.head()",
   "id": "a7c15465e0fca30",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "  Dream Symbol                                     Interpretation\n",
       "0     Aardvark  To see an aardvark in your dream indicates tha...\n",
       "1  Abandonment  To dream that you are abandoned suggests that ...\n",
       "2    Abduction  To dream of being abducted indicates that you ...\n",
       "3    Aborigine  To see an Aborigine in your dream represents b...\n",
       "4     Abortion  To dream that you have an abortion suggests th..."
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dream Symbol</th>\n",
       "      <th>Interpretation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Aardvark</td>\n",
       "      <td>To see an aardvark in your dream indicates tha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Abandonment</td>\n",
       "      <td>To dream that you are abandoned suggests that ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Abduction</td>\n",
       "      <td>To dream of being abducted indicates that you ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Aborigine</td>\n",
       "      <td>To see an Aborigine in your dream represents b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Abortion</td>\n",
       "      <td>To dream that you have an abortion suggests th...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Now, we will use pretrained LLMs in order to extract the given keywords from the keywords dataset , from the dream text description from the dream text dataset.",
   "id": "bd509c434a4e3b8d"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### **GPT2**\n",
    "***"
   ],
   "id": "b6c5d2fa9f32bfe5"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-13T21:39:36.596114Z",
     "start_time": "2025-04-13T21:32:54.369789Z"
    }
   },
   "cell_type": "code",
   "source": "extract_and_save_keywords_from_dataframes()",
   "id": "26b7a0f6bf84fe5a",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\NLP\\dream_interpreter\\Dream-Interpreter\\.venv\\Lib\\site-packages\\huggingface_hub\\file_download.py:144: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\barak\\.cache\\huggingface\\hub\\models--togethercomputer--RedPajama-INCITE-7B-Chat. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "Fetching 2 files: 100%|██████████| 2/2 [03:32<00:00, 106.04s/it]\n",
      "Loading checkpoint shards: 100%|██████████| 2/2 [02:53<00:00, 86.79s/it] \n",
      "Device set to use cuda:0\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mRuntimeError\u001B[39m                              Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[11]\u001B[39m\u001B[32m, line 1\u001B[39m\n\u001B[32m----> \u001B[39m\u001B[32m1\u001B[39m \u001B[43mextract_and_save_keywords_from_dataframes\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32mC:\\NLP\\dream_interpreter\\Dream-Interpreter\\keyword_extractor.py:60\u001B[39m, in \u001B[36mextract_and_save_keywords_from_dataframes\u001B[39m\u001B[34m(config_path)\u001B[39m\n\u001B[32m     58\u001B[39m tokenizer = AutoTokenizer.from_pretrained(config[\u001B[33m'\u001B[39m\u001B[33mmodel\u001B[39m\u001B[33m'\u001B[39m][\u001B[33m'\u001B[39m\u001B[33mname\u001B[39m\u001B[33m'\u001B[39m])\n\u001B[32m     59\u001B[39m model = AutoModelForCausalLM.from_pretrained(config[\u001B[33m'\u001B[39m\u001B[33mmodel\u001B[39m\u001B[33m'\u001B[39m][\u001B[33m'\u001B[39m\u001B[33mname\u001B[39m\u001B[33m'\u001B[39m])\n\u001B[32m---> \u001B[39m\u001B[32m60\u001B[39m pipe = \u001B[43mpipeline\u001B[49m\u001B[43m(\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mtext-generation\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m=\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtokenizer\u001B[49m\u001B[43m=\u001B[49m\u001B[43mtokenizer\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m     61\u001B[39m \u001B[43m                \u001B[49m\u001B[43mdevice\u001B[49m\u001B[43m=\u001B[49m\u001B[43mconfig\u001B[49m\u001B[43m[\u001B[49m\u001B[33;43m'\u001B[39;49m\u001B[33;43mmodel\u001B[39;49m\u001B[33;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m[\u001B[49m\u001B[33;43m'\u001B[39;49m\u001B[33;43mdevice\u001B[39;49m\u001B[33;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     63\u001B[39m candidate_keywords = keywords_df[config[\u001B[33m'\u001B[39m\u001B[33mdata\u001B[39m\u001B[33m'\u001B[39m][\u001B[33m'\u001B[39m\u001B[33mkeywords_column\u001B[39m\u001B[33m'\u001B[39m]].tolist()\n\u001B[32m     64\u001B[39m top_n_keywords = config[\u001B[33m'\u001B[39m\u001B[33mmodel\u001B[39m\u001B[33m'\u001B[39m][\u001B[33m'\u001B[39m\u001B[33mnum_keywords\u001B[39m\u001B[33m'\u001B[39m]\n",
      "\u001B[36mFile \u001B[39m\u001B[32mC:\\NLP\\dream_interpreter\\Dream-Interpreter\\.venv\\Lib\\site-packages\\transformers\\pipelines\\__init__.py:1180\u001B[39m, in \u001B[36mpipeline\u001B[39m\u001B[34m(task, model, config, tokenizer, feature_extractor, image_processor, processor, framework, revision, use_fast, token, device, device_map, torch_dtype, trust_remote_code, model_kwargs, pipeline_class, **kwargs)\u001B[39m\n\u001B[32m   1177\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m processor \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[32m   1178\u001B[39m     kwargs[\u001B[33m\"\u001B[39m\u001B[33mprocessor\u001B[39m\u001B[33m\"\u001B[39m] = processor\n\u001B[32m-> \u001B[39m\u001B[32m1180\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mpipeline_class\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m=\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mframework\u001B[49m\u001B[43m=\u001B[49m\u001B[43mframework\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtask\u001B[49m\u001B[43m=\u001B[49m\u001B[43mtask\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32mC:\\NLP\\dream_interpreter\\Dream-Interpreter\\.venv\\Lib\\site-packages\\transformers\\pipelines\\text_generation.py:99\u001B[39m, in \u001B[36mTextGenerationPipeline.__init__\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m     98\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34m__init__\u001B[39m(\u001B[38;5;28mself\u001B[39m, *args, **kwargs):\n\u001B[32m---> \u001B[39m\u001B[32m99\u001B[39m     \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m.\u001B[49m\u001B[34;43m__init__\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    100\u001B[39m     \u001B[38;5;28mself\u001B[39m.check_model_type(\n\u001B[32m    101\u001B[39m         TF_MODEL_FOR_CAUSAL_LM_MAPPING_NAMES \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m.framework == \u001B[33m\"\u001B[39m\u001B[33mtf\u001B[39m\u001B[33m\"\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m MODEL_FOR_CAUSAL_LM_MAPPING_NAMES\n\u001B[32m    102\u001B[39m     )\n\u001B[32m    103\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[33m\"\u001B[39m\u001B[33mprefix\u001B[39m\u001B[33m\"\u001B[39m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m._preprocess_params:\n\u001B[32m    104\u001B[39m         \u001B[38;5;66;03m# This is very specific. The logic is quite complex and needs to be done\u001B[39;00m\n\u001B[32m    105\u001B[39m         \u001B[38;5;66;03m# as a \"default\".\u001B[39;00m\n\u001B[32m    106\u001B[39m         \u001B[38;5;66;03m# It also defines both some preprocess_kwargs and generate_kwargs\u001B[39;00m\n\u001B[32m    107\u001B[39m         \u001B[38;5;66;03m# which is why we cannot put them in their respective methods.\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32mC:\\NLP\\dream_interpreter\\Dream-Interpreter\\.venv\\Lib\\site-packages\\transformers\\pipelines\\base.py:996\u001B[39m, in \u001B[36mPipeline.__init__\u001B[39m\u001B[34m(self, model, tokenizer, feature_extractor, image_processor, processor, modelcard, framework, task, args_parser, device, torch_dtype, binary_output, **kwargs)\u001B[39m\n\u001B[32m    989\u001B[39m \u001B[38;5;66;03m# We shouldn't call `model.to()` for models loaded with accelerate as well as the case that model is already on device\u001B[39;00m\n\u001B[32m    990\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m (\n\u001B[32m    991\u001B[39m     \u001B[38;5;28mself\u001B[39m.framework == \u001B[33m\"\u001B[39m\u001B[33mpt\u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m    992\u001B[39m     \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mself\u001B[39m.model.device != \u001B[38;5;28mself\u001B[39m.device\n\u001B[32m    993\u001B[39m     \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28misinstance\u001B[39m(\u001B[38;5;28mself\u001B[39m.device, \u001B[38;5;28mint\u001B[39m) \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mself\u001B[39m.device < \u001B[32m0\u001B[39m)\n\u001B[32m    994\u001B[39m     \u001B[38;5;129;01mand\u001B[39;00m hf_device_map \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m    995\u001B[39m ):\n\u001B[32m--> \u001B[39m\u001B[32m996\u001B[39m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m.\u001B[49m\u001B[43mto\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mdevice\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    998\u001B[39m \u001B[38;5;66;03m# If the model can generate:\u001B[39;00m\n\u001B[32m    999\u001B[39m \u001B[38;5;66;03m# 1 - create a local generation config. This is done to avoid side-effects on the model as we apply local\u001B[39;00m\n\u001B[32m   1000\u001B[39m \u001B[38;5;66;03m# tweaks to the generation config.\u001B[39;00m\n\u001B[32m   1001\u001B[39m \u001B[38;5;66;03m# 2 - load the assistant model if it is passed.\u001B[39;00m\n\u001B[32m   1002\u001B[39m \u001B[38;5;28mself\u001B[39m.assistant_model, \u001B[38;5;28mself\u001B[39m.assistant_tokenizer = load_assistant_model(\n\u001B[32m   1003\u001B[39m     \u001B[38;5;28mself\u001B[39m.model, kwargs.pop(\u001B[33m\"\u001B[39m\u001B[33massistant_model\u001B[39m\u001B[33m\"\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m), kwargs.pop(\u001B[33m\"\u001B[39m\u001B[33massistant_tokenizer\u001B[39m\u001B[33m\"\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m)\n\u001B[32m   1004\u001B[39m )\n",
      "\u001B[36mFile \u001B[39m\u001B[32mC:\\NLP\\dream_interpreter\\Dream-Interpreter\\.venv\\Lib\\site-packages\\transformers\\modeling_utils.py:3698\u001B[39m, in \u001B[36mPreTrainedModel.to\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   3693\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m dtype_present_in_args:\n\u001B[32m   3694\u001B[39m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[32m   3695\u001B[39m             \u001B[33m\"\u001B[39m\u001B[33mYou cannot cast a GPTQ model in a new `dtype`. Make sure to load the model using `from_pretrained` using the desired\u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m   3696\u001B[39m             \u001B[33m\"\u001B[39m\u001B[33m `dtype` by passing the correct `torch_dtype` argument.\u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m   3697\u001B[39m         )\n\u001B[32m-> \u001B[39m\u001B[32m3698\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m.\u001B[49m\u001B[43mto\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32mC:\\NLP\\dream_interpreter\\Dream-Interpreter\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1343\u001B[39m, in \u001B[36mModule.to\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1340\u001B[39m         \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m   1341\u001B[39m             \u001B[38;5;28;01mraise\u001B[39;00m\n\u001B[32m-> \u001B[39m\u001B[32m1343\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_apply\u001B[49m\u001B[43m(\u001B[49m\u001B[43mconvert\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32mC:\\NLP\\dream_interpreter\\Dream-Interpreter\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:903\u001B[39m, in \u001B[36mModule._apply\u001B[39m\u001B[34m(self, fn, recurse)\u001B[39m\n\u001B[32m    901\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m recurse:\n\u001B[32m    902\u001B[39m     \u001B[38;5;28;01mfor\u001B[39;00m module \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m.children():\n\u001B[32m--> \u001B[39m\u001B[32m903\u001B[39m         \u001B[43mmodule\u001B[49m\u001B[43m.\u001B[49m\u001B[43m_apply\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfn\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    905\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mcompute_should_use_set_data\u001B[39m(tensor, tensor_applied):\n\u001B[32m    906\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m torch._has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001B[32m    907\u001B[39m         \u001B[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001B[39;00m\n\u001B[32m    908\u001B[39m         \u001B[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001B[39;00m\n\u001B[32m   (...)\u001B[39m\u001B[32m    913\u001B[39m         \u001B[38;5;66;03m# global flag to let the user control whether they want the future\u001B[39;00m\n\u001B[32m    914\u001B[39m         \u001B[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32mC:\\NLP\\dream_interpreter\\Dream-Interpreter\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:903\u001B[39m, in \u001B[36mModule._apply\u001B[39m\u001B[34m(self, fn, recurse)\u001B[39m\n\u001B[32m    901\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m recurse:\n\u001B[32m    902\u001B[39m     \u001B[38;5;28;01mfor\u001B[39;00m module \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m.children():\n\u001B[32m--> \u001B[39m\u001B[32m903\u001B[39m         \u001B[43mmodule\u001B[49m\u001B[43m.\u001B[49m\u001B[43m_apply\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfn\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    905\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mcompute_should_use_set_data\u001B[39m(tensor, tensor_applied):\n\u001B[32m    906\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m torch._has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001B[32m    907\u001B[39m         \u001B[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001B[39;00m\n\u001B[32m    908\u001B[39m         \u001B[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001B[39;00m\n\u001B[32m   (...)\u001B[39m\u001B[32m    913\u001B[39m         \u001B[38;5;66;03m# global flag to let the user control whether they want the future\u001B[39;00m\n\u001B[32m    914\u001B[39m         \u001B[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32mC:\\NLP\\dream_interpreter\\Dream-Interpreter\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:930\u001B[39m, in \u001B[36mModule._apply\u001B[39m\u001B[34m(self, fn, recurse)\u001B[39m\n\u001B[32m    926\u001B[39m \u001B[38;5;66;03m# Tensors stored in modules are graph leaves, and we don't want to\u001B[39;00m\n\u001B[32m    927\u001B[39m \u001B[38;5;66;03m# track autograd history of `param_applied`, so we have to use\u001B[39;00m\n\u001B[32m    928\u001B[39m \u001B[38;5;66;03m# `with torch.no_grad():`\u001B[39;00m\n\u001B[32m    929\u001B[39m \u001B[38;5;28;01mwith\u001B[39;00m torch.no_grad():\n\u001B[32m--> \u001B[39m\u001B[32m930\u001B[39m     param_applied = \u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[43mparam\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    931\u001B[39m p_should_use_set_data = compute_should_use_set_data(param, param_applied)\n\u001B[32m    933\u001B[39m \u001B[38;5;66;03m# subclasses may have multiple child tensors so we need to use swap_tensors\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32mC:\\NLP\\dream_interpreter\\Dream-Interpreter\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1329\u001B[39m, in \u001B[36mModule.to.<locals>.convert\u001B[39m\u001B[34m(t)\u001B[39m\n\u001B[32m   1322\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m convert_to_format \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m t.dim() \u001B[38;5;129;01min\u001B[39;00m (\u001B[32m4\u001B[39m, \u001B[32m5\u001B[39m):\n\u001B[32m   1323\u001B[39m         \u001B[38;5;28;01mreturn\u001B[39;00m t.to(\n\u001B[32m   1324\u001B[39m             device,\n\u001B[32m   1325\u001B[39m             dtype \u001B[38;5;28;01mif\u001B[39;00m t.is_floating_point() \u001B[38;5;129;01mor\u001B[39;00m t.is_complex() \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[32m   1326\u001B[39m             non_blocking,\n\u001B[32m   1327\u001B[39m             memory_format=convert_to_format,\n\u001B[32m   1328\u001B[39m         )\n\u001B[32m-> \u001B[39m\u001B[32m1329\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mt\u001B[49m\u001B[43m.\u001B[49m\u001B[43mto\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m   1330\u001B[39m \u001B[43m        \u001B[49m\u001B[43mdevice\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1331\u001B[39m \u001B[43m        \u001B[49m\u001B[43mdtype\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mif\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mt\u001B[49m\u001B[43m.\u001B[49m\u001B[43mis_floating_point\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01mor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mt\u001B[49m\u001B[43m.\u001B[49m\u001B[43mis_complex\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01melse\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[32m   1332\u001B[39m \u001B[43m        \u001B[49m\u001B[43mnon_blocking\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1333\u001B[39m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1334\u001B[39m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mNotImplementedError\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[32m   1335\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mstr\u001B[39m(e) == \u001B[33m\"\u001B[39m\u001B[33mCannot copy out of meta tensor; no data!\u001B[39m\u001B[33m\"\u001B[39m:\n",
      "\u001B[31mRuntimeError\u001B[39m: CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "2137fd422450c910"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
