{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "709bb27208e23ba4",
   "metadata": {},
   "source": [
    "## **Step 1 - keywords Extraction**\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5af564d8f04df39",
   "metadata": {},
   "source": [
    "We have two datasets, one with dream text descriptions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1ecfbd7e24c7e53",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-03T16:35:41.288127Z",
     "start_time": "2025-05-03T16:35:30.582438Z"
    }
   },
   "outputs": [],
   "source": [
    "from keyword_extractor import read_datasets, extract_and_save_keywords_from_dataframes\n",
    "from yaml_parser import load_config\n",
    "config = load_config()\n",
    "dream_df, keywords_df = read_datasets(config)\n",
    "dream_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62c56a04aa56a02",
   "metadata": {},
   "source": [
    "And another one with interpretations of dreams according to keywords:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7c15465e0fca30",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-03T16:35:42.053745Z",
     "start_time": "2025-05-03T16:35:42.043610Z"
    }
   },
   "outputs": [],
   "source": [
    "keywords_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd509c434a4e3b8d",
   "metadata": {},
   "source": [
    "Then, we used a pretrained Sentence transformer to encode the dream embeddings and keyword embeddings and try to extract the most significant keywords from each dream."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6c5d2fa9f32bfe5",
   "metadata": {},
   "source": [
    "### **all-MiniLM-L6-v2**\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26b7a0f6bf84fe5a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-03T16:38:32.546001Z",
     "start_time": "2025-05-03T16:35:42.137333Z"
    }
   },
   "outputs": [],
   "source": [
    "dream_df = extract_and_save_keywords_from_dataframes()\n",
    "dream_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e58dd5943a0d1a8",
   "metadata": {},
   "source": [
    "To view the dataframe better, We will filter out the interesting columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "821e6946480217fa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-03T16:38:32.645080Z",
     "start_time": "2025-05-03T16:38:32.638181Z"
    }
   },
   "outputs": [],
   "source": [
    "columns_to_show = ['text_dream', 'Dream Symbol']\n",
    "dream_df[columns_to_show]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31a7e75c",
   "metadata": {},
   "source": [
    "## Step 2 - Summarize interpretations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de0d4023e12db1af",
   "metadata": {},
   "source": [
    "After extracting the meaningful keywords, we tried to fetch the matching interpretation for each extracted keyword and use a pretrained LLM to summarize these interpretations into one interpretation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "896dc1f6",
   "metadata": {},
   "source": [
    "### Load data and prepare (small) dataset for experimenting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4328b3ac",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-03T16:38:32.861969Z",
     "start_time": "2025-05-03T16:38:32.769750Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from transformers import pipeline\n",
    "from utils import  release_all_gpu_memory, save_df_as_pretty_html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "851684ea",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-03T16:38:32.904974Z",
     "start_time": "2025-05-03T16:38:32.898488Z"
    }
   },
   "outputs": [],
   "source": [
    "from summarizer import load_causal_model, batch_generate_interpretations\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65307ac5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-03T16:38:33.267335Z",
     "start_time": "2025-05-03T16:38:32.978454Z"
    }
   },
   "outputs": [],
   "source": [
    "dream_df= pd.read_csv('datasets/rsos_dream_data.tsv', sep='\\t')\n",
    "dream_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82be03f2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-03T16:38:33.335708Z",
     "start_time": "2025-05-03T16:38:33.320705Z"
    }
   },
   "outputs": [],
   "source": [
    "keywords_df = pd.read_csv(\"datasets/fixed_interpretations.csv\")\n",
    "keywords_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9555f979",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-03T16:38:33.485734Z",
     "start_time": "2025-05-03T16:38:33.475281Z"
    }
   },
   "outputs": [],
   "source": [
    "exmpl = dream_df[dream_df[\"text_dream\"].str.len()< 300]     # Limit the dream length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59cec8b1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-03T16:38:33.635438Z",
     "start_time": "2025-05-03T16:38:33.626113Z"
    }
   },
   "outputs": [],
   "source": [
    "exmpl = exmpl[[\"text_dream\",\"Dream Symbol\"]].sample(5, random_state=45)     # Create sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e8ecf4b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-03T16:38:33.690634Z",
     "start_time": "2025-05-03T16:38:33.684338Z"
    }
   },
   "outputs": [],
   "source": [
    "exmpl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8e51e4a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-03T16:38:33.747066Z",
     "start_time": "2025-05-03T16:38:33.742049Z"
    }
   },
   "outputs": [],
   "source": [
    "exmpl[\"Dream Symbol\"]   # keywords of the sample"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a6893ed4a4144bd",
   "metadata": {},
   "source": [
    "Now, we will create a prompt for the LLM. The prompt will include a request for the LLM to summarize the interpretations. It will get the dream description, the keywords, and the interpretations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3572d85a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-03T16:38:33.902756Z",
     "start_time": "2025-05-03T16:38:33.889756Z"
    }
   },
   "outputs": [],
   "source": [
    "dataset = []\n",
    "\n",
    "prmt = \"\"\"Given dream description, interpret the meaning of the dream. \n",
    "Provided also are the dream symbols that appear in the dream and their meanings. \n",
    "Use the dream symbols meanings to help you interpret the dream. \"\"\".replace(\"\\n\", \" \")\n",
    "\n",
    "\n",
    "for i, ex in exmpl.iterrows():\n",
    "    #print(ex)\n",
    "    keys = ex[\"Dream Symbol\"].split(\",\")[:5]\n",
    "    \n",
    "    #print(keys)\n",
    "    syms = keywords_df[keywords_df[\"Dream Symbol\"].isin(keys)]\n",
    "\n",
    "    descr = syms.apply(lambda r: f' - {r[\"Dream Symbol\"]}:  {r[\"Interpretation\"]}', axis = 1)\n",
    "    item = {\n",
    "        \"prompt\": prmt, \n",
    "        \"dream\": ex[\"text_dream\"],\n",
    "        \"symbols\": \"\\n\".join(descr),\n",
    "        }\n",
    "    dataset.append(item)\n",
    "    \n",
    "\n",
    "dataset = pd.DataFrame(dataset)\n",
    "dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e117bdf",
   "metadata": {},
   "source": [
    "### Summarize with flan-T5-large model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccb75fd2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-03T16:38:34.232059Z",
     "start_time": "2025-05-03T16:38:34.043026Z"
    }
   },
   "outputs": [],
   "source": [
    "release_all_gpu_memory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16073714",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-03T16:38:35.957547Z",
     "start_time": "2025-05-03T16:38:34.274307Z"
    }
   },
   "outputs": [],
   "source": [
    "# Step 1: Load FLAN-T5 model and tokenizer\n",
    "model_name = \"google/flan-t5-large\"\n",
    "model_name_short = model_name.split(\"/\")[-1]\n",
    "device = 0 if torch.cuda.is_available() else -1\n",
    "model, tokenizer = load_causal_model(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "034d08aa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-03T16:38:42.022208Z",
     "start_time": "2025-05-03T16:38:35.994449Z"
    }
   },
   "outputs": [],
   "source": [
    "text2text_generator = pipeline(\n",
    "        \"text2text-generation\",\n",
    "        model=model,\n",
    "        tokenizer=tokenizer,\n",
    "        max_length=1024,           # âœ… allow longer input\n",
    "        truncation=True,           # âœ… ensure truncation at tokenizer level\n",
    "        device=device,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb00ba2d4b78df0e",
   "metadata": {},
   "source": [
    "Create interpretations in batches:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d3b2a8e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-03T16:39:00.197400Z",
     "start_time": "2025-05-03T16:38:42.151455Z"
    }
   },
   "outputs": [],
   "source": [
    "tstp = datetime.now().strftime(r\"%y.%m.%d-%H\")\n",
    "result_df = batch_generate_interpretations(dataset, text2text_generator, batch_size=10, max_length=250)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b868a34a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-03T16:39:00.264108Z",
     "start_time": "2025-05-03T16:39:00.258724Z"
    }
   },
   "outputs": [],
   "source": [
    "postproc = lambda out: out[\"generated_text\"].strip()\n",
    "result_df[\"interpretation\"] = result_df[\"interpretation\"].apply(postproc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b435acdf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-03T16:39:00.314631Z",
     "start_time": "2025-05-03T16:39:00.304180Z"
    }
   },
   "outputs": [],
   "source": [
    "result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5019cae1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-03T16:39:00.390995Z",
     "start_time": "2025-05-03T16:39:00.384987Z"
    }
   },
   "outputs": [],
   "source": [
    "result_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ac4b6293edbffe0",
   "metadata": {},
   "source": [
    "We saw that the interpretations are not quite good, and not that related to the dream description. We tried to save the dataframe for further research and saw that the problem applies to many cells and tried another model called Mistral."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f42a0964",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-03T16:39:00.487159Z",
     "start_time": "2025-05-03T16:39:00.482158Z"
    }
   },
   "outputs": [],
   "source": [
    "# TODO: Should probably delete that cell\n",
    "# save_df = result_df[['prompt', 'symbols','dream', 'interpretation']]\n",
    "#\n",
    "# path = f\"output/{model_name_short}_{tstp}\"\n",
    "#\n",
    "# save_df_as_pretty_html(save_df, path + \".html\")\n",
    "#\n",
    "# save_df.to_csv(path + \".csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e78ec2c5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-03T16:39:00.543634Z",
     "start_time": "2025-05-03T16:39:00.527153Z"
    }
   },
   "outputs": [],
   "source": [
    "result_df.interpretation.str.len()  # TODO: Remember why we sorted interpretations by length..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3da433d4",
   "metadata": {},
   "source": [
    "### Summarize with Mistral model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "607f318b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-03T16:39:00.626314Z",
     "start_time": "2025-05-03T16:39:00.622493Z"
    }
   },
   "outputs": [],
   "source": [
    "from summarizer import load_mistral_4bit_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b50747c8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-03T16:39:00.681488Z",
     "start_time": "2025-05-03T16:39:00.673977Z"
    }
   },
   "outputs": [],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0263914",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-03T16:39:01.156368Z",
     "start_time": "2025-05-03T16:39:00.760460Z"
    }
   },
   "outputs": [],
   "source": [
    "release_all_gpu_memory([\"model\", \"tokenizer\", \"text2text_generator\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "272ff4c7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-03T16:41:49.322476Z",
     "start_time": "2025-05-03T16:39:01.241846Z"
    }
   },
   "outputs": [],
   "source": [
    "print(\"Loading Mistral-7B-Instruct in 4-bit...\")\n",
    "model_name = \"mistralai/Mistral-7B-Instruct-v0.2\"\n",
    "model_name_short = model_name.split(\"/\")[-1]\n",
    "  \n",
    "max_new_tokens=256\n",
    "\n",
    "model, tokenizer = load_mistral_4bit_model(model_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2d43e75",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-03T16:42:59.468860Z",
     "start_time": "2025-05-03T16:42:59.459981Z"
    }
   },
   "outputs": [],
   "source": [
    "model_pipeline = pipeline(\n",
    "        \"text-generation\",\n",
    "        model=model,\n",
    "        tokenizer=tokenizer,\n",
    "        max_new_tokens=max_new_tokens,\n",
    "        do_sample=False\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aff5df7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(\"\\nðŸ§  Running interpretations...\")\n",
    "tstp = datetime.now().strftime(r\"%y.%m.%d-%H\")\n",
    "\n",
    "result_df = batch_generate_interpretations(dataset, model_pipeline, batch_size=10)\n",
    "#print(result_df[[\"dream\", \"interpretation\"]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09636b4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "postproc = lambda out: out[0][\"generated_text\"].split(\"Interpretation:\")[-1].strip()\n",
    "result_df[\"interpretation\"] = result_df[\"interpretation\"].apply(postproc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d4fa381",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "522a4d54",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "save_df = result_df[['prompt', 'symbols','dream', 'interpretation']]\n",
    "\n",
    "path = f\"output/{model_name_short}_{tstp}\"\n",
    "save_df_as_pretty_html(save_df, path + \".html\")\n",
    "\n",
    "save_df.to_csv(path + \".csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54bbf3d0879e878",
   "metadata": {},
   "source": [
    "It didn't seem to help... So we then tried to improve our keyword extraction using:\n",
    "1. First - semantic search to narrow down the search of the keywords to only the semantically close ones.\n",
    "2. Second - MMR (Maximal Marginal Relevance) to increase the diversity of keywords extracted from the dream."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e54edc9d7f6bbc9",
   "metadata": {},
   "source": [
    "#TODO: Summarize better_keywords_extraction.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e12f81a5af772a13",
   "metadata": {},
   "source": [
    "## **Evaluation**\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa317c15fd3c5bd3",
   "metadata": {},
   "source": [
    "We evaluated the performance of the dream interpretation using BLEU,perplexity,ROUGE, and BERT. **It's important to mention: evaluation was tested on a small sample of 5 rows, and also the dream interpretation was compared to the dream itself and that might be the reason for the small values of the metrics**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfc4b89ecbcc5a7b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-03T17:06:39.432583Z",
     "start_time": "2025-05-03T17:06:34.660817Z"
    }
   },
   "outputs": [],
   "source": [
    "from evaluation import evaluate_dream_interpretations\n",
    "import pandas as pd\n",
    "dreams_interpretations_df = pd.read_csv('datasets/Mistral-7B-Instruct-v0.2_25.04.17-16.csv')\n",
    "dreams_interpretations_df = evaluate_dream_interpretations(dreams_interpretations_df)\n",
    "dreams_interpretations_df.to_csv('datasets/Mistral-7B-Instruct-v0.2_25.04.17-16_evaluated.csv', index=False)\n",
    "dreams_interpretations_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22d13ba9772d675f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-03T17:11:52.535627Z",
     "start_time": "2025-05-03T17:11:51.989396Z"
    }
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "\n",
    "# Create figure with subplots for non-perplexity scores\n",
    "fig1, (ax1, ax2) = plt.subplots(2, 1, figsize=(12, 10))\n",
    "plt.grid()\n",
    "\n",
    "# Plot distributions without perplexity\n",
    "scores_without_perplexity = ['BLEU', 'ROUGE', 'BERT']\n",
    "for score in scores_without_perplexity:\n",
    "    sns.kdeplot(data=dreams_interpretations_df[score], label=score, ax=ax1)\n",
    "ax1.set_title('Score Distributions (BLEU, ROUGE, BERT)')\n",
    "ax1.legend()\n",
    "\n",
    "# Calculate statistics for heatmap without perplexity\n",
    "stats_df = pd.DataFrame()\n",
    "for score in scores_without_perplexity:\n",
    "    stats_df[score] = [\n",
    "        dreams_interpretations_df[score].min(),\n",
    "        dreams_interpretations_df[score].max(),\n",
    "        dreams_interpretations_df[score].mean(),\n",
    "        dreams_interpretations_df[score].median(),\n",
    "        stats.mode(dreams_interpretations_df[score])[0]\n",
    "    ]\n",
    "stats_df.index = ['Min', 'Max', 'Average', 'Median', 'Mode']\n",
    "\n",
    "# Plot heatmap\n",
    "sns.heatmap(stats_df, annot=True, fmt='.3f', cmap='YlOrRd', ax=ax2)\n",
    "ax2.set_title('Score Statistics (BLEU, ROUGE, BERT)')\n",
    "plt.tight_layout()\n",
    "\n",
    "# Create separate figure for perplexity\n",
    "fig2, (ax3, ax4) = plt.subplots(2, 1, figsize=(12, 10))\n",
    "\n",
    "# Plot perplexity distribution\n",
    "sns.kdeplot(data=dreams_interpretations_df['perplexity'], ax=ax3)\n",
    "ax3.set_title('Perplexity Distribution')\n",
    "\n",
    "# Calculate perplexity statistics\n",
    "perplexity_stats = pd.DataFrame({\n",
    "    'perplexity': [\n",
    "        dreams_interpretations_df['perplexity'].min(),\n",
    "        dreams_interpretations_df['perplexity'].max(),\n",
    "        dreams_interpretations_df['perplexity'].mean(),\n",
    "        dreams_interpretations_df['perplexity'].median(),\n",
    "        stats.mode(dreams_interpretations_df['perplexity'])[0]\n",
    "    ]\n",
    "})\n",
    "perplexity_stats.index = ['Min', 'Max', 'Average', 'Median', 'Mode']\n",
    "\n",
    "# Plot perplexity heatmap\n",
    "sns.heatmap(perplexity_stats, annot=True, fmt='.3f', cmap='YlOrRd', ax=ax4)\n",
    "ax4.set_title('Perplexity Statistics')\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36dbda02eb4d1cd5",
   "metadata": {},
   "source": [
    "We can draw the following conclusions:\n",
    "1. The bleu score is incredibly low (a good result should be 20-40, we didn't even get 1...). This means that there is a weak overlap between the dream and its interpretation.\n",
    "2. Same for the Rouge.\n",
    "3. BERT averages at 0.6, which is not that bad considering that a good value is 0.85â€“0.9 that indicates some semantic similarity between the dream and its interpretation.\n",
    "4. perplexity is terrible since a good value is under 20...\n",
    "5. We interpret the results using this table:\n",
    "| **Metric** | **High Score Meaning** | **Low Score Meaning** | **Preferred Score** | **Typical Values for Good Results** | **Why?** |\n",
    "| --- | --- | --- | --- | --- | --- |\n",
    "| **BLEU** | High n-gram overlap between reference and candidate text | Low n-gram overlap between reference and candidate text | **High** | 20â€“40 (moderate), 40+ (good) | High BLEU indicates the candidate text closely matches the reference text. |\n",
    "| **Perplexity** | Candidate text is unpredictable and diverges from reference distribution | Candidate text is predictable, fluent, and aligned with reference distribution | **Low** | < 20 (for good results) | Low perplexity shows that the candidate text is fluent, consistent, and aligned with the reference. |\n",
    "| **ROUGE** | More overlapping n-grams (e.g., unigrams, bigrams) and higher recall of key phrases | Fewer overlapping n-grams and poor recall of key phrases | **High** | 30â€“50 (good), 50+ (very good) | High ROUGE suggests greater similarity between the candidate and reference texts. |\n",
    "| **BERTScore** | Strong semantic similarity between the candidate and reference text | Weak semantic similarity between the candidate and reference text | **High** | 0.85â€“0.98 (good) | Higher BERTScore reflects that the candidate preserves the meaning of the reference text. |\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dabf1e9f90ff0ab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".dream",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
