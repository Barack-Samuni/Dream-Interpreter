{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "709bb27208e23ba4",
   "metadata": {},
   "source": [
    "## **Step 1 - keywords Extraction**\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5af564d8f04df39",
   "metadata": {},
   "source": [
    "We have two datasets, one with dream text descriptions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1ecfbd7e24c7e53",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-13T21:23:35.718332Z",
     "start_time": "2025-04-13T21:23:35.469996Z"
    }
   },
   "outputs": [],
   "source": [
    "from keyword_extractor import read_datasets, extract_and_save_keywords_from_dataframes\n",
    "from yaml_parser import load_config\n",
    "config = load_config()\n",
    "dream_df, keywords_df = read_datasets(config)\n",
    "dream_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62c56a04aa56a02",
   "metadata": {},
   "source": [
    "And another one with interpretations of dreams according to keywords:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7c15465e0fca30",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-13T21:23:35.755134Z",
     "start_time": "2025-04-13T21:23:35.747133Z"
    }
   },
   "outputs": [],
   "source": [
    "keywords_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd509c434a4e3b8d",
   "metadata": {},
   "source": [
    "Now, we will use pretrained LLMs in order to extract the given keywords from the keywords dataset , from the dream text description from the dream text dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6c5d2fa9f32bfe5",
   "metadata": {},
   "source": [
    "### **GPT2**\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26b7a0f6bf84fe5a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-13T21:39:36.596114Z",
     "start_time": "2025-04-13T21:32:54.369789Z"
    }
   },
   "outputs": [],
   "source": [
    "dream_df = extract_and_save_keywords_from_dataframes()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31a7e75c",
   "metadata": {},
   "source": [
    "## Step 2 - Summarize interpretations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "896dc1f6",
   "metadata": {},
   "source": [
    "### Load data and prepare (small) dataset for experimenting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4328b3ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from transformers import pipeline\n",
    "from utils import  release_all_gpu_memory, save_df_as_pretty_html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "851684ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from summarizer import load_causal_model, batch_generate_interpretations\n",
    "\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9555f979",
   "metadata": {},
   "outputs": [],
   "source": [
    "exmpl = dream_df[dream_df[\"text_dream\"].str.len()< 300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59cec8b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "exmpl = exmpl[[\"text_dream\",\"Dream Symbol\"]].sample(5, random_state=45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e8ecf4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "exmpl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8e51e4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "exmpl[\"Dream Symbol\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3572d85a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = []\n",
    "\n",
    "prmt = \"\"\"Given dream description, interpret the meaning of the dream. \n",
    "Provided also are the dream symbols that appear in the dream and their meanings. \n",
    "Use the dream symbols meanings to help you interpret the dream. \"\"\".replace(\"\\n\", \" \")\n",
    "\n",
    "\n",
    "for i, ex in dream_df.iterrows():\n",
    "    #print(ex)\n",
    "    keys = ex[\"Dream Symbol\"].split(\",\")[:5]\n",
    "    \n",
    "    #print(keys)\n",
    "    syms = keywords_df[keywords_df[\"Dream Symbol\"].isin(keys)]\n",
    "\n",
    "    descr = syms.apply(lambda r: f' - {r[\"Dream Symbol\"]}:  {r[\"Interpretation\"]}', axis = 1)\n",
    "    item = {\n",
    "        \"prompt\": prmt, \n",
    "        \"dream\": ex[\"text_dream\"],\n",
    "        \"symbols\": \"\\n\".join(descr),\n",
    "        }\n",
    "    dataset.append(item)\n",
    "    \n",
    "\n",
    "dataset = pd.DataFrame(dataset)\n",
    "dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e117bdf",
   "metadata": {},
   "source": [
    "### Summarize with flan-T5-large model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccb75fd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "release_all_gpu_memory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16073714",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Load FLAN-T5 model and tokenizer\n",
    "model_name = \"google/flan-t5-large\"\n",
    "model_name_short = model_name.split(\"/\")[-1]\n",
    "device = 0 if torch.cuda.is_available() else -1\n",
    "model, tokenizer = load_causal_model(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "034d08aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "text2text_generator = pipeline(\n",
    "        \"text2text-generation\",\n",
    "        model=model,\n",
    "        tokenizer=tokenizer,\n",
    "        max_length=1024,           # âœ… allow longer input\n",
    "        truncation=True,           # âœ… ensure truncation at tokenizer level\n",
    "        device=device,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d3b2a8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tstp = datetime.now().strftime(r\"%y.%m.%d-%H\")\n",
    "result_df = batch_generate_interpretations(dataset, text2text_generator, batch_size=100, max_length=250)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b868a34a",
   "metadata": {},
   "outputs": [],
   "source": [
    "postproc = lambda out: out[\"generated_text\"].strip()\n",
    "result_df[\"interpretation\"] = result_df[\"interpretation\"].apply(postproc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b435acdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5019cae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c59c1e02",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name_short"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f42a0964",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_df = result_df[['prompt', 'symbols','dream', 'interpretation']]\n",
    "\n",
    "path = f\"output/{model_name_short}_{tstp}\"\n",
    "\n",
    "save_df_as_pretty_html(save_df, path + \".html\")\n",
    "\n",
    "save_df.to_csv(path + \".csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e78ec2c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df.interpretation.str.len()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8773b1f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv(path + \".csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baeb937d",
   "metadata": {},
   "outputs": [],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3da433d4",
   "metadata": {},
   "source": [
    "### Summarize with Mistral model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "607f318b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from summarizer import load_mistral_4bit_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b50747c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0263914",
   "metadata": {},
   "outputs": [],
   "source": [
    "release_all_gpu_memory([\"model\", \"tokenizer\", \"text2text_generator\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "272ff4c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Loading Mistral-7B-Instruct in 4-bit...\")\n",
    "\n",
    "model_name = \"mistralai/Mistral-7B-Instruct-v0.2\"\n",
    "model_name_short = model_name.split(\"/\")[-1]\n",
    "\n",
    "model_family=\"decoder\"\n",
    "  \n",
    "# max_new_tokens=256         max_new_tokens=max_new_tokens,\n",
    "\n",
    "model, tokenizer = load_mistral_4bit_model(model_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9cc28d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Sample prompt length (characters): {len(sample_prompt)}\")\n",
    "optimal_batch_size = find_max_batch_size(model, tokenizer, sample_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2d43e75",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_pipeline = pipeline(\n",
    "        \"text-generation\",\n",
    "        model=model,\n",
    "        batch_size=4,\n",
    "        tokenizer=tokenizer,\n",
    "        max_length = model.config.max_position_embeddings,\n",
    "        do_sample=False\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1911eb23",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.pad_token = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dfb5369",
   "metadata": {},
   "outputs": [],
   "source": [
    "l = len(dataset)\n",
    "l\n",
    "batch_size = int(l/1)\n",
    "batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1338e22d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from summarizer import PromptFormatter\n",
    "\n",
    "formatter = PromptFormatter(model_family)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aff5df7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(\"\\nðŸ§  Running interpretations...\")\n",
    "tstp = datetime.now().strftime(r\"%y.%m.%d-%H\")\n",
    "\n",
    "result_df = batch_generate_interpretations(dataset, model_pipeline, formatter, batch_size=67)\n",
    "#print(result_df[[\"dream\", \"interpretation\"]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d66e60c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tok = model_pipeline.tokenizer\n",
    "tok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69796e7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tok.model_max_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "701fe16a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.config.max_position_embeddings\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c8b56e3",
   "metadata": {},
   "source": [
    "## Trash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94871894",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a50d7a6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tzd = tokenizer.tokenize(sample_prompt, truncation=False, max_length=1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ca3135d",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(tzd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09636b4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "postproc = lambda out: out[0][\"generated_text\"].split(\"Interpretation:\")[-1].strip()\n",
    "result_df[\"interpretation\"] = result_df[\"interpretation\"].apply(postproc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d4fa381",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "522a4d54",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "save_df = result_df[['prompt', 'symbols','dream', 'interpretation']]\n",
    "\n",
    "path = f\"output/{model_name_short}_{tstp}\"\n",
    "save_df_as_pretty_html(save_df, path + \".html\")\n",
    "\n",
    "save_df.to_csv(path + \".csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9906afb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[\"inputs\"] = dataset.apply(lambda row: format_input(row[\"prompt\"], row[\"dream\"], row[\"symbols\"]), axis=1)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e7b5194",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[\"input_len\"] = dataset[\"inputs\"].str.len()\n",
    "dataset.sort_values(\"input_len\", ascending=False, inplace=True)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3068914a",
   "metadata": {},
   "outputs": [],
   "source": [
    "shorter_dataset = dataset[dataset.input_len<7000]\n",
    "shorter_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f2053f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "shorter_dataset.input_len.hist(bins=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c757ab79",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_df_as_pretty_html(dataset[:100], \"output/long_inputs.html\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".dream",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
