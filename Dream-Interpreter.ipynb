{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "709bb27208e23ba4",
   "metadata": {},
   "source": [
    "## **Step 1 - keywords Extraction**\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5af564d8f04df39",
   "metadata": {},
   "source": [
    "We have two datasets, one with dream text descriptions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1ecfbd7e24c7e53",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-13T21:23:35.718332Z",
     "start_time": "2025-04-13T21:23:35.469996Z"
    }
   },
   "outputs": [],
   "source": [
    "from keyword_extractor import read_datasets, extract_and_save_keywords_from_dataframes\n",
    "from yaml_parser import load_config\n",
    "config = load_config()\n",
    "dream_df, keywords_df = read_datasets(config)\n",
    "dream_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62c56a04aa56a02",
   "metadata": {},
   "source": [
    "And another one with interpretations of dreams according to keywords:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7c15465e0fca30",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-13T21:23:35.755134Z",
     "start_time": "2025-04-13T21:23:35.747133Z"
    }
   },
   "outputs": [],
   "source": [
    "keywords_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd509c434a4e3b8d",
   "metadata": {},
   "source": [
    "Now, we will use pretrained LLMs in order to extract the given keywords from the keywords dataset , from the dream text description from the dream text dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6c5d2fa9f32bfe5",
   "metadata": {},
   "source": [
    "### **GPT2**\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26b7a0f6bf84fe5a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-13T21:39:36.596114Z",
     "start_time": "2025-04-13T21:32:54.369789Z"
    }
   },
   "outputs": [],
   "source": [
    "dream_df = extract_and_save_keywords_from_dataframes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "803344e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "css = \"\"\"\n",
    "    .table-style {\n",
    "                  width: 100%;\n",
    "                  border-style: solid;\n",
    "                  border-width: 5px;\n",
    "}\n",
    "\n",
    "    .table-style td {\n",
    "                  white-space:pre\n",
    "                  width: 100px;\n",
    "                  border-style: solid;\n",
    "                  border-width: 5px;\n",
    "}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f6dac7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dream_df[[\"text_dream\",\"Dream Symbol\"]][:100].style\\\n",
    "  .set_table_attributes('class=\"table-style\"')\\\n",
    "  .to_html(\"datasets/dream_and_its_keys.html\", index=False, classes=css, border=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "721b6935",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "31a7e75c",
   "metadata": {},
   "source": [
    "## Step 2 - Summarize interpretations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "896dc1f6",
   "metadata": {},
   "source": [
    "### Load data and prepare (small) dataset for experimenting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4328b3ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from transformers import pipeline\n",
    "from utils import  release_all_gpu_memory, save_df_as_pretty_html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "851684ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from summarizer import load_causal_model, batch_generate_interpretations\n",
    "\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65307ac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "dream_df= pd.read_csv('datasets/rsos_dream_data.tsv', sep='\\t')\n",
    "dream_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82be03f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "keywords_df = pd.read_csv(\"datasets/fixed_interpretations.csv\")\n",
    "keywords_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9555f979",
   "metadata": {},
   "outputs": [],
   "source": [
    "exmpl = dream_df[dream_df[\"text_dream\"].str.len()< 300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59cec8b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "exmpl = exmpl[[\"text_dream\",\"Dream Symbol\"]].sample(5, random_state=44)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e8ecf4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "exmpl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8e51e4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "exmpl[\"Dream Symbol\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3572d85a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = []\n",
    "\n",
    "prmt = \"\"\"Given dream description, interpret the meaning of the dream. \n",
    "Provided also are the dream symbols that appear in the dream and their meanings. \n",
    "Use the dream symbols meanings to help you interpret the dream. \"\"\".replace(\"\\n\", \" \")\n",
    "\n",
    "rs = 42\n",
    "\n",
    "for i, ex in exmpl.iterrows():\n",
    "    #print(ex)\n",
    "    keys = ex[\"Dream Symbol\"].split(\",\")[:5]\n",
    "    \n",
    "    #print(keys)\n",
    "    syms = keywords_df[keywords_df[\"Dream Symbol\"].isin(keys)]\n",
    "\n",
    "    descr = syms.apply(lambda r: f' - {r[\"Dream Symbol\"]}:  {r[\"Interpretation\"]}', axis = 1)\n",
    "    item = {\n",
    "        \"prompt\": prmt, \n",
    "        \"dream\": ex[\"text_dream\"],\n",
    "        \"symbols\": \"\\n\".join(descr),\n",
    "        }\n",
    "    dataset.append(item)\n",
    "    rs += 1\n",
    "    \n",
    "\n",
    "dataset = pd.DataFrame(dataset)\n",
    "dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e117bdf",
   "metadata": {},
   "source": [
    "### Summarize with flan-T5-large model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccb75fd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "release_all_gpu_memory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16073714",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Load FLAN-T5 model and tokenizer\n",
    "model_name = \"google/flan-t5-large\"\n",
    "model_name_short = model_name.split(\"/\")[-1]\n",
    "device = 0 if torch.cuda.is_available() else -1\n",
    "model, tokenizer = load_causal_model(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "034d08aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "text2text_generator = pipeline(\n",
    "        \"text2text-generation\",\n",
    "        model=model,\n",
    "        tokenizer=tokenizer,\n",
    "        max_length=1024,           # ✅ allow longer input\n",
    "        truncation=True,           # ✅ ensure truncation at tokenizer level\n",
    "        device=device,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d3b2a8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tstp = datetime.now().strftime(r\"%y.%m.%d-%H\")\n",
    "result_df = batch_generate_interpretations(dataset, text2text_generator, batch_size=1, max_length=250)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b868a34a",
   "metadata": {},
   "outputs": [],
   "source": [
    "postproc = lambda out: out[\"generated_text\"].strip()\n",
    "result_df[\"interpretation\"] = result_df[\"interpretation\"].apply(postproc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b435acdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5019cae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f42a0964",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_df = result_df[['prompt', 'symbols','dream', 'interpretation']]\n",
    "\n",
    "path = f\"output/{model_name_short}_{tstp}\"\n",
    "\n",
    "save_df_as_pretty_html(save_df, path + \".html\")\n",
    "\n",
    "save_df.to_csv(path + \".csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e78ec2c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df.interpretation.str.len()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3da433d4",
   "metadata": {},
   "source": [
    "### Summarize with Mistral model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "607f318b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from summarizer import load_mistral_4bit_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b50747c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0263914",
   "metadata": {},
   "outputs": [],
   "source": [
    "release_all_gpu_memory([\"model\", \"tokenizer\", \"text2text_generator\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "272ff4c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Loading Mistral-7B-Instruct in 4-bit...\")\n",
    "\n",
    "model_name = \"mistralai/Mistral-7B-Instruct-v0.2\"\n",
    "model_name_short = model_name.split(\"/\")[-1]\n",
    "  \n",
    "max_new_tokens=256\n",
    "\n",
    "model, tokenizer = load_mistral_4bit_model(model_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2d43e75",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_pipeline = pipeline(\n",
    "        \"text-generation\",\n",
    "        model=model,\n",
    "        tokenizer=tokenizer,\n",
    "        max_new_tokens=max_new_tokens,\n",
    "        do_sample=False\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aff5df7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(\"\\n🧠 Running interpretations...\")\n",
    "tstp = datetime.now().strftime(r\"%y.%m.%d-%H\")\n",
    "\n",
    "result_df = batch_generate_interpretations(dataset, model_pipeline, batch_size=4)\n",
    "#print(result_df[[\"dream\", \"interpretation\"]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09636b4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "postproc = lambda out: out[0][\"generated_text\"].split(\"Interpretation:\")[-1].strip()\n",
    "result_df[\"interpretation\"] = result_df[\"interpretation\"].apply(postproc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d4fa381",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "522a4d54",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "save_df = result_df[['prompt', 'symbols','dream', 'interpretation']]\n",
    "\n",
    "path = f\"output/{model_name_short}_{tstp}\"\n",
    "save_df_as_pretty_html(save_df, path + \".html\")\n",
    "\n",
    "save_df.to_csv(path + \".csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".dream",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
